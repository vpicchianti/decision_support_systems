{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycountry_convert\n",
    "# !pip install reverse_geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from xml.etree import ElementTree as ET\n",
    "import reverse_geocode as rg\n",
    "import pycountry_convert as pc\n",
    "import csv\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_already_in_table(diz_row, table, generare_ID):\n",
    "        \n",
    "    ''' this function checks if the given row (diz_row) is already present in the table\n",
    "\n",
    "    Args:\n",
    "        - diz_row (dict): the row to check\n",
    "        - table (dict): table to check against\n",
    "        - generare_ID (bool): whether to generate an ID or if the ID is already provided (True if we need to generate it)\n",
    "\n",
    "    Returns:\n",
    "        - int or None: If the row is already present, returns the corresponding ID\n",
    "                      If the row is not present, returns None\n",
    "    '''\n",
    "        \n",
    "    if not generare_ID: # ho già ID nel Police.csv, non dobbiamo crearlo noi #è il caso ad esempio di Date \n",
    "        # check se l'ID è già presente in table\n",
    "        id_to_check = None\n",
    "        for k, v in diz_row.items():  \n",
    "            if k.endswith('_fk') or k.endswith('_id'):\n",
    "                id_to_check = v  \n",
    "                break \n",
    "        if id_to_check in table.keys():\n",
    "            return id_to_check\n",
    "        return None # non è ancora presente \n",
    "     \n",
    "    else: # l'ID non è già dato ma va generato, quindi non posso fare un check su ID (non ce l'ho)\n",
    "        valori_row = list(diz_row.values())\n",
    "        for k, v in table.items():\n",
    "            if valori_row == v[:-1]:\n",
    "                return int(k)\n",
    "    return None\n",
    "\n",
    "\n",
    "def add_record(diz_row, table, generare_ID):\n",
    "\n",
    "    '''this function adds a record (row) to the corrisponding table\n",
    "\n",
    "    Args:\n",
    "        - diz_row (dict): the row to add\n",
    "        - table (dict): the table to add the row to\n",
    "        - generare_ID (bool): whether to generate an ID or if the ID is already provided (True if we need to generate it)\n",
    "\n",
    "    Returns:\n",
    "        - int : the ID of the added row, whether it is the one already provided or the newly created one\n",
    "    '''\n",
    "\n",
    "    id_key = None\n",
    "\n",
    "    for k, v in diz_row.items():\n",
    "        if k.endswith('_fk') or k.endswith('_id'):\n",
    "            id_key = k\n",
    "            break\n",
    "\n",
    "    if not table:   # la tabella è vuota \n",
    "        if generare_ID:\n",
    "            table[1] = list(diz_row.values()) + [1]\n",
    "            return 1\n",
    "        else:\n",
    "            if id_key is not None:\n",
    "                id = diz_row[id_key]\n",
    "                table[id] = [v for k, v in diz_row.items() if k != id_key] + [id]\n",
    "                #table[id] = [{k: v for k, v in diz_row.items()}]\n",
    "                return id\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    already_in = is_already_in_table(diz_row, table, generare_ID)\n",
    "    if already_in is None:\n",
    "        if generare_ID: # adesso devo creare ID incrementale\n",
    "            pk = list(table.keys())[-1] + 1\n",
    "            table[pk] = list(diz_row.values())  + [pk]\n",
    "            return pk \n",
    "        else:  # date\n",
    "            id = None\n",
    "            for k, v in diz_row.items():  \n",
    "                if k.endswith('_fk') or k.endswith('_id'):\n",
    "                    id = v  \n",
    "                    break\n",
    "            table[id] =  [v for k, v in diz_row.items() if k != id_key] + [id]\n",
    "            return id\n",
    "\n",
    "    else: # already_in not None \n",
    "\n",
    "        return already_in\n",
    "\n",
    "\n",
    "def data_into_tables(rows, tables):\n",
    "\n",
    "    '''this function insert data into tables\n",
    "\n",
    "    Args:\n",
    "        - rows (list): list of rows to insert\n",
    "        - tables (dict): dictionary containing table names as keys and tuples (table, generate_ID) as values \n",
    "\n",
    "    Returns:\n",
    "        - list: list of IDs corresponding to the inserted rows (these represent foreing keys in Custody)\n",
    "    '''\n",
    "        \n",
    "    ids = []\n",
    "    for table_name, row in zip(tables.keys(), rows):\n",
    "        table, generate_ID = tables[table_name] \n",
    "        if table_name == 'geography':\n",
    "            geo_key = (row['latitude'], row['longitude'])\n",
    "            if geo_key in table:\n",
    "                geo_fk = table[geo_key]\n",
    "            else:\n",
    "                # generate a new geo_id if not found\n",
    "                new_geo_id = len(table) + 1\n",
    "                table[geo_key] = new_geo_id \n",
    "                geo_fk = new_geo_id\n",
    "            ids_line = geo_fk  # assign geo_fk to ids_line\n",
    "        else:\n",
    "            ids_line = add_record(row, table, generate_ID)\n",
    "        ids.append(ids_line)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gravity(age, type, status, partecipant_info):\n",
    "    \n",
    "    ''' this functions compute the crime gravity attribute for a given participant\n",
    "\n",
    "    Args:\n",
    "        - age (dict): dictionary representing the age-related factors in the gravity computation\n",
    "        - type (dict): dictionary representing the type-related factors in the gravity computation\n",
    "        - status (dict): dictionary representing the status-related factors in the gravity computation\n",
    "        - partecipant_info (dict): dictionary containing information about the participant, including:\n",
    "            - 'participant_age_group' (str): age group of the participant\n",
    "            - 'participant_type' (str): type of the participant\n",
    "            - 'participant_status' (str): status of the participant\n",
    "\n",
    "    Returns:\n",
    "        - float: the computed crime gravity value based on the given factors and participant information\n",
    "    '''\n",
    "\n",
    "    partecipant_age = partecipant_info.get('participant_age_group', None)\n",
    "    partecipant_type = partecipant_info.get('participant_type', None)\n",
    "    partecipant_status = partecipant_info.get('participant_status', None)\n",
    "    crime_gravity = age[partecipant_age] * type[partecipant_type] * status[partecipant_status]\n",
    "\n",
    "    return crime_gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_police(file_police, dimensional_tables, incident, custody, age, type, status): \n",
    "\n",
    "    '''this function process the police data from a CSV file, updating dimensional tables and incident/custody dictionaries\n",
    "\n",
    "    Args:\n",
    "        - file_police (str): path to the CSV file containing police data\n",
    "        - dimensional_tables (dict): dictionary containing dimensional tables (partecipant, gun, geo, date)\n",
    "        - incident (set): set to store unique incident IDs\n",
    "        - custody (dict): dictionary to store custody records\n",
    "        - age (dict): dictionary representing age-related factors for computing crime gravity\n",
    "        - type (dict): dictionary representing type-related factors for computing crime gravity\n",
    "        - status (dict): dictionary representing status-related factors for computing crime gravity\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "        \n",
    "    with open(file_police, 'r') as police:\n",
    "        header = None\n",
    "        for line in police:\n",
    "            if header is None:\n",
    "                header = line.strip().split(',')\n",
    "            else:\n",
    "                row_values = line.strip().split(',')\n",
    "                row_dict = {header[i]: row_values[i] for i in range(len(header))}\n",
    "\n",
    "                partec_info = {\n",
    "                    'participant_age_group': row_dict['participant_age_group'],\n",
    "                    'participant_gender': row_dict['participant_gender'],\n",
    "                    'participant_status': row_dict['participant_status'],\n",
    "                    'participant_type': row_dict['participant_type']\n",
    "                }\n",
    "                geo_info = {\n",
    "                    'latitude': float(row_dict['latitude']),\n",
    "                    'longitude': float(row_dict['longitude'])\n",
    "                }\n",
    "                gun_info = {\n",
    "                    'gun_stolen': row_dict['gun_stolen'],\n",
    "                    'gun_type': row_dict['gun_type']\n",
    "                }\n",
    "                date_info = {\n",
    "                    'date_fk': int(row_dict['date_fk'])\n",
    "                }\n",
    "\n",
    "\n",
    "                # add data into dimension tables\n",
    "                partecipant_fk, gun_fk, date_fk, geo_fk = data_into_tables([partec_info, gun_info, geo_info, date_info],  dimensional_tables)\n",
    "                \n",
    "                # aggiungi incident info\n",
    "                incident_id = int(row_dict['incident_id'])\n",
    "                incident.add(incident_id)\n",
    "\n",
    "                # calcola crime_gravity \n",
    "                crime_gravity = compute_gravity(age, type, status, partec_info)\n",
    "                \n",
    "                custody_id = int(row_dict['custody_id'])\n",
    "                custody_record = [custody_id, partecipant_fk, gun_fk, geo_fk, date_fk, crime_gravity, incident_id] \n",
    "                custody[custody_id] = custody_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml_file(file_path):\n",
    "    ''' ths function reads data from an XML file and extract relevant information\n",
    "\n",
    "    Args:\n",
    "        - file_path (str): path to the XML file\n",
    "\n",
    "    Returns:\n",
    "        - list: list of dictionaries containing extracted data\n",
    "    '''\n",
    "        \n",
    "    xml_data = []\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    for row in root.findall('row'):\n",
    "        data = {\n",
    "            'date': row.find('date').text,\n",
    "            'date_pk': row.find('date_pk').text\n",
    "        }\n",
    "        xml_data.append(data)\n",
    "    return xml_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_date(date_table, xml_data):\n",
    "    '''this functions enrich the date table with information from XML data\n",
    "\n",
    "    Args:\n",
    "        - date_table (dict): the date table to enrich\n",
    "        - xml_data (list): list of dictionaries containing XML data with 'date' and 'date_pk' keys\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    for row in xml_data:\n",
    "        date_pk = int(row['date_pk'])\n",
    "        date = row['date'].split()[0].replace('-', '') # we want date to be in format YYYYMMDD without - or /\n",
    "\n",
    "        date_object = datetime.datetime.strptime(date, '%Y%m%d')\n",
    "\n",
    "        # extract year, month, and day \n",
    "        year = date_object.year\n",
    "        month = date_object.month\n",
    "        day = date_object.day\n",
    "\n",
    "        # compute quarter \n",
    "        quarter = (month - 1) // 3 + 1\n",
    "\n",
    "        # compute the name of the weekday as a string \n",
    "        datetime_obj = datetime.date(year, month, day)\n",
    "        day_of_week_str = datetime_obj.strftime(\"%A\")\n",
    "\n",
    "        date_table[date_pk].extend([date, day, month, year, quarter, day_of_week_str])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_geography(geography):\n",
    "\n",
    "    ''' this function enriches the geography dictionary with additional information (city, country, continent, lat, long) using reverse geocode\n",
    "\n",
    "    Args:\n",
    "        - geography (dict): a dictionary where keys are coordinate tuples (latitude, longitude)\n",
    "                            and values are geography IDs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    def country_to_continent(country_name):\n",
    "\n",
    "        ''' this helping function maps a country name to its continent\n",
    "\n",
    "        Args:\n",
    "            - country_name (str): the name of the country\n",
    "\n",
    "        Returns:\n",
    "            - str: continent name\n",
    "        '''\n",
    "\n",
    "        country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        return country_continent_name\n",
    "\n",
    "    coords = [k for k in geography.keys()]\n",
    "    results = (rg.search(coords))\n",
    "    coordinates_to_results = dict(zip(coords, results))\n",
    "\n",
    "    for coord, geo_id in geography.items():\n",
    "        if coord in coordinates_to_results:\n",
    "            result = coordinates_to_results[coord]\n",
    "            continent = country_to_continent(result['country'])\n",
    "            geography[coord] = [geo_id, result['city'], result['country'], continent, coord[0], coord[1]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(structures):\n",
    "\n",
    "    ''' this function writes data from structures to CSV files\n",
    "\n",
    "    Args:\n",
    "        - structures (list): list of tuples containing data, filename and header \n",
    "                             each tuple represents a structure to be written to a CSV file\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    \n",
    "    for data, filename, header in structures:\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            \n",
    "            if header:\n",
    "                writer.writerow(header)\n",
    "\n",
    "            if isinstance(data, dict):\n",
    "                for row in data.values():\n",
    "                    row_list = list(row) if isinstance(row, set) else row\n",
    "                    writer.writerow(row_list)\n",
    "            elif isinstance(data, set):  \n",
    "                writer.writerow(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialization of structures representing both fact and dimension tables\n",
    "# dimension tables: partecipant, gun, geography, dates and incident\n",
    "# each dimensional table is initialized as an empty dictionary, and specific flags indicate whether we need generate ID\n",
    "\n",
    "\n",
    "partecipant = {}\n",
    "geography = {}\n",
    "gun = {}\n",
    "dates = {}\n",
    "incident = set()\n",
    "custody = {}\n",
    "\n",
    "dimensional_tables = {\n",
    "    'partecipant': (partecipant, True) ,  #True if we need to generate the ID, False otherwise\n",
    "    'gun': (gun, True) ,\n",
    "    'geography': (geography, True) ,\n",
    "    'dates': (dates, False)\n",
    "}\n",
    "\n",
    "file_partecipant_age = 'dict_partecipant_age.json'\n",
    "file_partecipant_status = 'dict_partecipant_status.json'\n",
    "file_partecipant_type = 'dict_partecipant_type.json'\n",
    "file_police = 'Police.csv'\n",
    "file_xml = 'dates.xml'\n",
    "\n",
    "with open(file_partecipant_age, 'r') as F1:\n",
    "    age = json.load(F1)    \n",
    "with open(file_partecipant_type, 'r') as F2:\n",
    "    type = json.load(F2)\n",
    "with open(file_partecipant_status, 'r') as F3:\n",
    "    status = json.load(F3)\n",
    "\n",
    "\n",
    "process_police(file_police, dimensional_tables, incident, custody, age, type, status)\n",
    "\n",
    "enrich_date(dates, read_xml_file(file_xml))\n",
    "enrich_geography(geography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "def slow_enrich_geography_with_geopy(geography):\n",
    "    geolocator = Nominatim(user_agent=\"reverse_geocoder_example\")\n",
    "\n",
    "    for location in geography.keys():\n",
    "            location_info = geolocator.reverse(location)\n",
    "            geography[location].append(location_info.address)\n",
    "\n",
    "\n",
    "subset_geography = dict(list(geography.items())[:100])\n",
    "\n",
    "\n",
    "start_time_slow = time.time()\n",
    "slow_enrich_geography_with_geopy(subset_geography)\n",
    "end_time_slow = time.time()\n",
    "elapsed_time_slow = end_time_slow - start_time_slow\n",
    "\n",
    "\n",
    "start_time_fast = time.time()\n",
    "enrich_geography(subset_geography)\n",
    "end_time_fast = time.time()\n",
    "elapsed_time_fast = end_time_fast - start_time_fast'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 90.79118800163269)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elapsed_time_fast, elapsed_time_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data into csv file to avoid losing data\n",
    "\n",
    "data = [\n",
    "    (partecipant, 'partecipant.csv', ['age_group', 'gender', 'status', 'type', 'partecipant_id']),\n",
    "    (gun, 'gun.csv', ['is_stolen', 'gun_type', 'gun_id']),\n",
    "    (dates, 'dates.csv', ['date_id', 'date', 'day', 'month', 'year', 'quarter','week_day']),\n",
    "    (custody, 'custody.csv', ['custody_id', 'partecipant_id', 'gun_id', 'geo_id', 'date_id', 'crime_gravity', 'incident_id']),\n",
    "    (incident, 'incident.csv', ['incident_id']),\n",
    "    (geography, 'geography.csv', ['geography_id', 'city', 'country', 'continent', 'latitude', 'longitude'])\n",
    "]\n",
    "\n",
    "write_to_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_csv_data_to_sql(file_path, table_name, connection_string):\n",
    "\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.fast_executemany=True\n",
    "\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        header = csv_reader.fieldnames\n",
    "        data = [tuple(row.values()) for row in csv_reader]\n",
    "\n",
    "\n",
    "    placeholders = ', '.join(['?' for _ in header])\n",
    "    sql_query = f\"INSERT INTO {table_name} ({', '.join(header)}) VALUES ({placeholders})\"\n",
    "\n",
    "    cursor.executemany(sql_query, data)\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_csv_data_to_sql_bis(file_path, table_name, connection_string):\n",
    " \n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.fast_executemany=True\n",
    "\n",
    "\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        header = csv_reader.fieldnames\n",
    "\n",
    " \n",
    "        placeholders = ', '.join(['?' for _ in header])\n",
    "        sql_query = f\"INSERT INTO {table_name} ({', '.join(header)}) VALUES ({placeholders})\"\n",
    "\n",
    "        data = [tuple(row[column] for column in header) for row in csv_reader]\n",
    "\n",
    "\n",
    "    cursor.executemany(sql_query, data)\n",
    "\n",
    "    connection.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'DRIVER={SQL Server};SERVER=tcp:lds.di.unipi.it;DATABASE=Group_ID_32_DB;UID=Group_ID_32;PWD=20RNW0GN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'dates.csv'\n",
    "table_name = 'dates'\n",
    "\n",
    "insert_csv_data_to_sql(csv_file_path, table_name, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'gun.csv'\n",
    "table_name = 'gun'\n",
    "\n",
    "insert_csv_data_to_sql(csv_file_path, table_name, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'partecipant.csv'\n",
    "table_name = 'partecipant'\n",
    "\n",
    "insert_csv_data_to_sql(csv_file_path, table_name, connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'incident.csv'\n",
    "table_name = 'incident'\n",
    "\n",
    "insert_csv_data_to_sql_bis(csv_file_path, table_name, connection_string)    # ok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'geography.csv'\n",
    "table_name = 'geography'\n",
    "\n",
    "insert_csv_data_to_sql(csv_file_path, table_name, connection_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_progetto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
